\chapter{Background}
\label{chapt:bg}
\section{Algorithm Overview}
\label{agloover}
Ant Colony Optimisation is a probabilistic technique usually used on problems which can be resolved by resolving an optimal path through a graphical representation of a given problem. Ant Colony Optimisation refers to a collection of methods and techniques which represent a specific family in swarm intelligence. Swarm intelligence \enquote{...deals with natural and artificial systems composed of many individuals that coordinate using decentralized control and self-organization. In particular, the discipline focuses on the collective behaviours that result from the local interactions of the individuals with each other and with their environment} \cite{SI:def}. In simpler terms each agent is simple and each agent follows a series of fairly simple rules as it performs its operations. If you increase the population size of these simple agents and allow them to communicate with each other and the world they are in then there will be an emergence of intelligence which would otherwise be unavailable to any individual agent. Ultimately each agent collectively works towards the same goal increasing the quality and appropriateness of the result.

The initial proposal for Ant Colony Optimisation came from Marco Dorigo et al. through the publication of his PhD in 1992 \cite{Dor1992:thesis}.The Algorithm is based upon the real world behaviour of ant colonies. Ants in the real world will generally always find the most optimal bath between two or more points, often described the route between their nest site and the location of the food source(s). As an Ant leaves the colony in search of a food source it begins to deposit a chemical trail (pheromone) which can be analysed by other agents in the population. The pheromone however is non consistently present once deposited, as this is the real world there are several factors which impact the concentration of the pheromone at any location once it has been deposited. Once an agent has deposited the pheromone it starts to decay overtime, and in the real world this could be accelerated by outside factors; such as adverse weather conditions. As the pheromone decays, new pheromone will be deposited at the same location by other agents in the colony also looking for a food source because of this, as more and more agents continue through their tour the locations which have the highest concentration of pheromone are generally the most traversed locations. Ultimately the locations with the highest concentration of pheromone will not only be the most frequently used, but together they will form the optimal route between the start location and the destination. This is due to the fact that the longer the route, the more susceptible pheromone levels are to decay, thus the longer paths will have less pheromone present. The pheromone levels are important because these levels are the main influence in the probabilistic function for any agent choosing its next location for any given intersection. The higher the concentration of pheromone, the greater the probability that the agent will choose this location as the next stop on its tour, however as this is probabilistic the agent may not always choose the location with the highest concentration allowing for other solutions to be sought after, allowing for a shift in the current best path.

\section{Double Bridge Experiment}
\label{dblbridge}
The double bridge experiment is an early experiment devised to help understand the real world behaviour of ants and their path finding capabilities. The double bridge experiment, as the name suggests involves a nest location separated from a single food source by two bridges. This experiment designed and carried out by Deneubourg and colleagues in 1989-1990 performed using real Argentine ants \cite{marcdorgio:book:doublebridges}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.5\textwidth]{Images/chapter1/doublebridge}
\caption{Image representing the Double Bridge Experiment. Image source \cite{doublebridges:image}}
\label{fig:doublebridge}
\end{figure}

\noindent
Figure \ref{fig:doublebridge} represents the scenario the Argentine ant were faced with for the Double Bridge Experiment. As previously stated in section \ref{agloover} the foraging behaviour of most ant species is dependant of communication using the pheromone deposits by each colony member during its tour. Initially there will be no pheromone trails for the ants to follow, so as the first ant approaches intersection marked \enquote{1} in figure \ref{fig:doublebridge} the probability that they choose the top path, or lower path is therefore 50\%. Regardless of which path the ant chose, pheromone will now be deposited on the path it took. Now the next ant will approach the intersection marked \enquote{1} however, as there is no an existing pheromone trail this ant now no longer has an equal probability to choose either path but instead is more likely to chose the same path that the previous ant had taken. This process will continue for every ant in the nest. The pheromone will however decay. Generally speaking as the bottom path is significantly longer than the top path, the pheromone deposited on its path will more subject to this decay, and will eventually have a lower pheromone concentration than the shorter top path. Overtime this will cause more and more ants to take the top path over the bottom path due to the higher pheromone level directly impacting the probability of the ant choosing this path. The same applies to intersection marked \enquote{2}, the ants will still tend to prefer the path with the greater pheromone concentration, the fact that the ant now has food does not affect the ants choice in anyway, aside from the fact that the ants new target is the nest and no longer the food source.

\section{Travelling Salesman Problem}
\label{tsp}
One of the most common applications for Ant Colony techniques is the Travelling Salesman Problem (TSP). The TSP consists of a graph of N cities, and you must find the shortest route between each of these N cities, however each city can only be visited exactly once. Generally this N value is often fairly large for example the Berlin52\cite{berlin52:source} is a variation of the TSP where this N value is 52. The number of possible routes between these 52 cities is incredibly large. The application of heuristic algorithms such at the Ant Colony methods enables solutions to be found within a reasonable time. One solution for the Berlin52.tsp problem is shown in figure \ref{fig:berlin52}.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.7]{Images/chapter1/tsp52}
\caption{One solution to the Berlin52.tsp problem plotted using GNU Plot. Modified version from original image source \cite{berlin52:image}}
\label{fig:berlin52}
\end{figure}

The TSP is not the only problem which can be tackled using the Ant Colony family of methods. As these methods have metaheuristic properties the general behaviours and structure can be applied to several other problems such as image segmentation however this application will not cover such problems and will focus on the TSP style problem.

\section{Ant System}
\label{sec:AntSystem}
The Ant System is the most basic implementation of an Ant Colony Optimisation method, because of this it provides the basis for other extensions and variations. This does not mean that the Ant System is lacklustre in performance. Due to its basic nature, the Ant System is ideal for demonstrating and teaching the behaviours of a virtual ant colony to someone, and it can be done regardless of their prior background knowledge. In this implementation there is no recollection of the best path between iterations and every agent is equal in terms of its importance in finding a solution.

\subsection{Forumlae}

Sections \ref{ASprob} and \ref{ASphero} refer to the underlying formulae which govern the agents pheromone deposits for a given edge and the probability for an agent to move to a specific location anytime it reaches an intersection.

\subsubsection{Probability}

The probability formula is as described in appendix B section \ref{sssec:probfuncsssec}. This is the function which drives the agents movements and enabled agents to generally pick the best looking path (path with the strongest pheromone concentration) whilst also allowing for agents to select other paths helping to prevent localised solutions forming.

\label{ASprob}

\subsubsection{pheromone}

The pheromone function for the Ant System algorithm is as described in appendix B section \ref{sssec:pherodepo}. This function is the real difference between the Ant System implementation and the Elitist Ant System.

\label{ASphero}

\section{Elitist Ant System}

The Elitist Ant System is the first adaptation to the initial Ant System algorithm. The Elitist Ant System is again, proposed by Marco Dorgio et al. in his 1992 PhD Thesis \cite{Dor1992:thesis}. The main difference between the Elitist Ant System and the Ant System is the fact that the best ants for a given iteration have pheromone deposited upon their route. This means that the best $x$ number of ants where $x$ is an integer representing the number of elite ants will have their routes remembered across iterations allowing the fact that they performed well to persist, with the intention to improve the performance of the population as a whole as the extra pheromone on these elite paths will increase the probability that any agent traverses an elite edge (an edge that is part of an elite path).

\subsection{Forumlae}

Sections \ref{EASprob} and \ref{EASphero} refer to the underlying formulae which govern the agents pheromone deposits for a given edge and the probability for an agent to move to a specific location anytime it reaches an intersection.

\subsubsection{Probability}
\label{EASprob}

The probability function for the Elitist Ant System remains the same as it is in the Ant System, see section \ref{ASprob} and appendix B section \ref{sssec:pherodepo}

\subsubsection{pheromone}
\label{EASphero}
As stated in section \ref{ASphero} the pheromone function is the main different between the two algorithm variations. This new pheromone function takes into account that there is elite agents and enables pheromone to be deposited along the current X elite paths.

\begin{figure}[H]
\Large
\begin{equation}
p_{xy}^{k} = (1 - \rho)\tau_{xy}^{k} + \Delta\tau_{xy}^{k} + e\Delta\tau_{xy}^{best}
\end{equation}

\caption{Algebraic model of the pheromone deposit function for the Elitist Ant System \cite{marcdorgio:book:EAS}}
\label{fig:EASpheromonefunc}

\end{figure}

The majority of the formula remains the same as defined in appendix B section \ref{sssec:pherodepo} however, there is the addition $e\Delta\tau_{xy}^{best}$. This is the part of the formula which is responsible for the pheromone deposit on the retained best (elite) paths currently found. $xy$ refers to the $x$ and $y$ coordinate for an edge in the best path this is where pheromone will be deposited. $best$ simply donates that this edge belongs to one of the currently stored best paths. The $e$ value is a constant, and varies between implementations. Research suggests that a good value for this weighted value, $e$ is $\frac{1}{4}\ .\ \#\ of \ nodes$ \cite{sjored:Thesus2012:evalue} however, there is evidence to support using $\#\ of \ nodes$ as the $e$ value\cite{marcdorgio:book:nopage}.

\section{Excisting Solutions}
\label{existingsolutions}
There are a number of pre-existing solutions which attempt visualise Ant Colony algorithms however, the majority of these based upon the authors experience are in fact subpar in what they visualise. Rather that visualising the algorithms execution in a logical manner, which would enable the user to understand what the algorithm is doing and how the best path converges over time, more often than not the existing solutions simply show the algorithms final state leaving the user confused.

Another problem with some of the existing solutions is that the graphical user interface for the application is far too inconsistent. Inconsistent here refers to the fact that there are a number of interaction method present which can be quite daunting for a user and therefore might cause a less than satisfactory experience for example, some features may require a user to use a scroll bar to set the value, others may require direct textual input and another feature may require the user to check a checkbox. In combination with this, the interfaces themselves are usually far too crowded and often unnecessary features for the current algorithm selection. If the user has selected that they want to use a specific variation of an Ant Colony algorithm then there is no point in allowing them to be able to modify a parameter which will have no impact on the current execution. The irrelevant interface elements can cause confusion amongst the users in terms of what in fact they are modifying and how it impacts the algorithms behaviour. 

One of the major problems the author faced when assessing the competition was the fact that there was rarely any visualisation of the agents themselves, this meant that you has to effectively guess which cities the agents were currently at. In addition to this as there was no visualisation of the agents there is no visualisation of the agents moving between the cities themselves thus, it was difficult to visualise the path the agents took aside from coming to your own conclusion based on the pheromone trails which were also often poorly represented.

\section{User Interaction Methods}
\label{uiMethods}
As discussed in section \ref{existingsolutions} the methods of user interaction must be superior to what is provided by the competition. This application will be authored in accordance with several preferred user interaction methods enabling a more user friednly experience for all users and not just those who are experienced with this or similar applications.

\subsection{Law of Context}

The law of context refers to the users expectation that they should only see interface controls relevant to the current object they want to control \cite{99designs:laws}. This relates to one of the fundamental problems found in competitor applications (see section \ref{existingsolutions}). Should the user request a change of algorithm type which requires an extension to default features, these new controls will be self-contained and represented suitably so the user knows that the news dialog or interaction method is a direct result of request a change in algorithm type, allowing for a logical mapping between their selection and the new control interface.

\subsection{Law of Feedback}

The law of feedback related the ideology that every significant action has some form of informative, relative feedback associated with it\cite{99designs:laws}. This enables the users to quickly develop an understanding of what interaction control which action allowing for a more enjoyable experience. This also covers any incorrect actions performed by the user. The application will be developed in such a way that any incorrect actions will be displayed to the user in a manner that anyone can understand and provide the user with the required knowledge to resolve said issue.

\subsection{Law of Easing}

The law of easing is very important, especially for this application. This law suggests that complex actions should be segmented into simpler steps to allow the user to comprehend what they are actually doing \cite{99designs:laws}. The way this application will adopt this is that rather than specifying all of the algorithmâ€™s parameters at once, each parameter will have its own method of interaction and its own series of user feedback prompts enabling any user to simply modify select parameters however they see fit, assuming the value is legal.

